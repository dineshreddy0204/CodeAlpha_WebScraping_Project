# ğŸ“Š CodeAlpha Internship â€“ Data Analytics Project

This repository contains my internship project for **CodeAlpha â€“ Data Analytics Domain**.  
The project successfully completes **Task 1 (Web Scraping)** and **Task 2 (Exploratory Data Analysis â€“ EDA)** using Python.

---

## âœ… Tasks Completed

### ğŸ”¹ Task 1: Web Scraping
- Extracted data from a public website using Python
- Collected structured data (Book Title, Price, Rating, Page Number)
- Stored the scraped data into a CSV file for analysis

**Technologies Used:**
- Python
- Requests
- BeautifulSoup
- Pandas

**Output File:**
- `data/books_large_data.csv` (1000 records)

**Script:**
- `scraper.py`

---

### ğŸ”¹ Task 2: Exploratory Data Analysis (EDA)
- Loaded the scraped dataset
- Explored dataset structure and data types
- Generated summary statistics
- Identified rating distribution
- Found top expensive books
- Created a detailed EDA report

**Analysis Performed:**
- Total records count
- Unique values
- Mean, min, max statistics
- Rating frequency analysis
- Data quality inspection

**Scripts & Output:**
- `eda.py`
- `eda_report.txt`

---

## ğŸ“ Project Structure
CodeAlpha_WebScraping_Project/ â”‚ â”œâ”€â”€ data/ â”‚   â””â”€â”€ books_large_data.csv â”‚ â”œâ”€â”€ scraper.py          # Task 1 â€“ Web Scraping â”œâ”€â”€ eda.py              # Task 2 â€“ Exploratory Data Analysis â”œâ”€â”€ eda_report.txt      # EDA results â”‚ â”œâ”€â”€ requirements.txt â”œâ”€â”€ README.md â””â”€â”€ .gitignore
---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
## Run Web Scraping(Task 1)
python scraper.py
## Run Exploratory Data Analysis(Task 2)
python eda.py